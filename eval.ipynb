{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import UNet2DConditionModel, DDPMScheduler, AutoencoderKL\n",
    "from transformers import CLIPTokenizer, CLIPTextModel\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "def generate_image(prompt, num_inference_steps=50, guidance_scale=7.5):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Load models\n",
    "    model_path = \"./ldm_checkpoints/epoch_2\"\n",
    "    \n",
    "    # Initialize models\n",
    "    unet = UNet2DConditionModel.from_pretrained(\n",
    "        os.path.join(model_path, \"unet\"),\n",
    "        use_safetensors=True\n",
    "    ).to(device)\n",
    "    text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "    tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    vae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-mse\").to(device)\n",
    "    scheduler = DDPMScheduler(num_train_timesteps=1000, beta_schedule=\"linear\")\n",
    "    \n",
    "    # Load training state if needed\n",
    "    checkpoint = torch.load(os.path.join(model_path, \"training_state.pth\"), map_location=torch.device('cpu'))\n",
    "    unet.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Set to evaluation mode\n",
    "    unet.eval()\n",
    "    text_encoder.eval()\n",
    "    vae.eval()\n",
    "    \n",
    "    # Encode text\n",
    "    text_input = tokenizer(\n",
    "        prompt,\n",
    "        padding=\"max_length\",\n",
    "        max_length=77,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    # Create uncond input for classifier free guidance\n",
    "    uncond_input = tokenizer(\n",
    "        [\"\"] * 1,  # empty string for unconditional guidance\n",
    "        padding=\"max_length\",\n",
    "        max_length=77,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        text_embeddings = text_encoder(text_input.input_ids)[0]\n",
    "        uncond_embeddings = text_encoder(uncond_input.input_ids)[0]\n",
    "        text_embeddings = torch.cat([uncond_embeddings, text_embeddings])\n",
    "    \n",
    "    # Initialize random latents\n",
    "    latents = torch.randn(\n",
    "        (1, 4, 64, 64)  # Make sure these dimensions match your training\n",
    "    ).to(device)\n",
    "    \n",
    "    latents = latents * scheduler.init_noise_sigma\n",
    "    \n",
    "    # Denoising loop\n",
    "    scheduler.set_timesteps(num_inference_steps)\n",
    "    \n",
    "    for t in scheduler.timesteps:\n",
    "        # Expand latents for classifier free guidance\n",
    "        latent_model_input = torch.cat([latents] * 2)\n",
    "        \n",
    "        # Scale latents according to timestep\n",
    "        latent_model_input = scheduler.scale_model_input(latent_model_input, t)\n",
    "        \n",
    "        # Predict noise residual\n",
    "        with torch.no_grad():\n",
    "            noise_pred = unet(\n",
    "                latent_model_input,\n",
    "                t,\n",
    "                encoder_hidden_states=text_embeddings\n",
    "            ).sample\n",
    "        \n",
    "        # Perform guidance\n",
    "        noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
    "        noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
    "        \n",
    "        # Compute previous noisy sample\n",
    "        latents = scheduler.step(noise_pred, t, latents).prev_sample\n",
    "    \n",
    "    # Decode latents to image\n",
    "    latents = 1 / 0.18215 * latents\n",
    "    with torch.no_grad():\n",
    "        image = vae.decode(latents).sample\n",
    "    \n",
    "    # Process image\n",
    "    image = (image / 2 + 0.5).clamp(0, 1)\n",
    "    image = image.detach().cpu().permute(0, 2, 3, 1).numpy()\n",
    "    image = (image * 255).round().astype(\"uint8\")\n",
    "    image = Image.fromarray(image[0])\n",
    "    \n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated image saved as 'generated_images/generated.png'\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "\n",
    "prompt = \"IMage of a cat\"\n",
    "image = generate_image(\n",
    "        prompt=prompt,\n",
    "        num_inference_steps=50,  # Increase for better quality, decrease for speed\n",
    "        guidance_scale=7.5  # Adjust for creativity vs prompt adherence\n",
    "    )\n",
    "    \n",
    "    # Save the generated image\n",
    "os.makedirs(\"generated_images\", exist_ok=True)\n",
    "image.save(\"generated_images/generated.png\")\n",
    "print(f\"Generated image saved as 'generated_images/generated.png'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
